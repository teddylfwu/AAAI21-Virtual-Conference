UID,title,authors,abstract,pdf_url,SessionInformation,presentation_id,GatherTownLink,ZoomLink
SMT-128,Unifying Principles and Metrics for Safe and Assistive AI,Siddharth Srivastava,"The prevalence and success of AI applications have been tempered by concerns about the controllability of AI systems about AI's impact on the future of work.  These concerns reflect two aspects of a central question: how  would  humans work with AI systems? While research on AI safety focuses on designing AI systems that allow humans to safely instruct and control AI systems, research on AI and the future of work focuses on the impact of AI on humans who may be unable to do so. This Blue Sky Ideas paper proposes a unifying set of declarative principles that enable a more uniform evaluation of arbitrary AI systems along multiple dimensions of the extent to which they are suitable for use by specific classes of human operators. It leverages recent AI research and the unique strengths of the field to develop human-centric principles for  AI systems that successfully address  the concerns noted above.",Blue Sky,"i.e., a link to the preprint version of each paper (probably hosted in AAAI official site). We also need a zipped file of all the papers in order to extract an image from each paper","e.g., 10:00-11:00, February 7 ","i.e., for the link https://slideslive.com/paper.SlidesLivePresentationID",Each paper has a unique GatherTownLink,We need this information if there is a paper presentation session
SMT-282,Towards a Unifying Framework for Formal Theories of Novelty,Terrance Boult|Mohsen M. Jafarzadeh|Toqueer Ahmad|Chunchun Li|Steve Cruz|Akshay Dhamija|Scheirer Walter|Derek Prijatelj|Joshua Alspector Joshua Alspector|Lawrence Holder|Przemyslaw Grabowicz|Roni Stern|Abhinav Shrivastava|Carl Vondrick,"Dealing with inputs that are novel, unknown, or out-of-distribution, is critical as an agent or other learning-based system moves from the lab to the open world. Novelty problems include being tolerant to novel perturbations, detecting when novel items are input, and adapting to novel inputs. While there has been significant research in these areas, a noticeable gap is the lack of a formalized definition of novelty that transcends problem domains. As a team of researchers spanning multiple research groups and different domains, we have seen, first hand, the difficulties that arise from ill-specified problems, inconsistent definitions,and terminology. We postulate that a unified framework for theories of novelty will help kick-start new research efforts and accelerate ongoing work to address these pressing problems. We collaborated to define this new unifying framework to ensure it could work across our different domains and research efforts. Herein, we present the first unified framework for formal theories of novelty and use the framework to define ten major sub-types of novelty. The formalization can be applied across a wide range of domains, from symbolic AI domains to reinforcement learning domains, as well as open world image recognition problems with incremental learning. Applying the proposed framework has allowed us to make predictions about the expected difficulty of novelty problems, which were then empirically verified.",Blue Sky,,,,,
SMT-351,Thinking Fast and Slow in AI,Francesca Rossi,"Humans possess a reasoning machinery that allows them to flexibly adapt to new environments, learn new skills with little data, and generalize to compactly communicate knowledge. Machines do not yet have a good grasp of these capabilities, although they can find hidden correlations in huge amounts of data, use them to make accurate predictions if trained with the appropriate data distribution, and effectively solve complex optimization problems on large search spaces, thus being successfully applicable in many application domains.Cognitive theories of human decision making, such as Kahneman's theory of thinking fast and slow (or system 1 and system 2), conjecture how humans reason and make decisions, and shed some light on the causes of humans' behavior, capabilities, and limitations. Although machines and humans are very different, we believe that it may be fruitful to exploit the knowledge we have of human decision making to define hypothesis on how to advance AI and provide it with some of the reasoning capabilities that humans have. Several researchers in the AI community are following this route, for example trying to add system 2 capabilities to machine learning approaches, which are more akin to system 1, or also by combining neuronal and symbolic approaches to AI. However, these attempts are usually focused on specific tasks. We believe that a general theory of machine decision making, inspired by what we know of human decision making, could significantly advance AI, both in autonomous systems and human-machine teams, and increase our understanding of both AI and the human mind.This talk aims to lay out the main relevant theories of human decision making, identify the main research questions in attempting to leverage them to advance AI's capabilities, and issue a call to action for the whole AI community to collectively work on answering such questions.",Blue Sky,,,,,
SMT-362,Lifelong and Continual Learning Dialogue Systems - Learning during Conversation,Bing Liu|Sahisnu Mazumder,"Dialogue systems, also called chatbots, are now used in a wide range of applications. However, they still have some major weaknesses. One key weakness is that they are typically trained from manually-labeled data and/or written with handcrafted rules, and their knowledge bases (KBs) are also compiled by human experts. Due to the huge amount of manual effort involved, they are difficult to scale and also tend to produce many errors ought to their limited ability to understand natural language and the limited knowledge in their KBs. Thus, the level of user satisfactory is often low. In this paper, we propose to dramatically improve this situation by endowing the system the ability to continually and actively learn (1) new world knowledge, (2) new language expressions to ground them to actions and (3) new conversational skills, during conversation by themselves so that as the systems chat more and more with users, they become more and more knowledgeable and are better and better able to understand diverse natural language expressions and improve their conversational skills. A key approach to achieving these is to exploit the multi-user environment of such systems to learn through interactions with users via verb and non-verb means. The paper discusses not only key challenges and promising directions to learn from users during conversation but also how to ensure the correctness of the learned knowledge.",Blue Sky,,,,,
SMT-427,Improving Causal Inference by Increasing Model Expressiveness,David Jensen,"The ability to learn and reason with causal knowledge is a key aspect of intelligent behavior.  In contrast to mere statistical association, knowledge of causation enables reasoning about the effects of actions.  Causal reasoning is vital for autonomous agents and for a range of applications in science, medicine, business, and government.  This paper argues that current methods for causal inference are hobbled because they use relatively inexpressive models.  Surprisingly, current causal models eschew nearly every major representational innovation common in a range of other fields both inside and outside of computer science, including representation of objects, relationships, time, space, and hierarchy.  Even more surprisingly, a range of recent research provides strong evidence that more expressive representations make possible causal inferences that are otherwise impossible and remove key biases that would otherwise afflict more naive inferences. New research on causal inference should target increases in expressiveness to improve accuracy and effectiveness.",Blue Sky,,,,,
SMT-230,Empowering Conversational AI is a Trip to Mars: Progress and Future of Open Domain Human-Computer Dialogues,Rui Yan|Wei Wu,"Dialogue systems powered by conversational artificial intelligence (AI) have never been so popular. Interacting with computer through languages reveals a more natural interface to give orders and acquire information—just like human communication. Due to promising potentials as virtual assistants and/or social bots, major NLP, AI and even Search & Mining communities are explicitly calling-out for contributions of conversational studies.Learning towards real conversational intelligence is a trip to Mars; perhaps we are yet on Earth.We have achieved substantial progress from recent research outputs. Still we have major obstacles to overcome. In this paper, we present an overview of progress and look forward to future trends so as to shed light on possible directions towards success.",Summary,,,,,
SMT-432,Thou Shalt Love Thy Neighbor as Thyself When Thou Play: Altruism in Game Theory,Jörg Rothe,"Game theory is typically used to model the interaction among (software) agents in multiagent systems and, therefore, is a key topic at leading AI conferences. Game-theoretic models, however, are often based on the assumption that agents act perfectly rational and narrowly selfish and are interested only in maximizing their own gains, no matter what the costs for the other agents are. This summary paper presents various ways of introducing certain notions of altruism into existing game-theoretic models, in both cooperative and noncooperative games, hoping that simulating altruistic behavior in AI systems will make AI more suitable for real-world applications—and thus the real world a better place.",Summary,,,,,
